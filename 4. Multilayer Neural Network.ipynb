{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Multilayer Neural Network\n",
    "For multi-layer neural network we do not use perceptrons.\n",
    "\n",
    "Multi-layer neural networks with linear neurons can be trained so that the output gets closer to the ideal output (truth).\n",
    "\n",
    "## 4.1. Linear Neurons\n",
    "The linear neuron has the following form:\n",
    "$$ y = \\sum_{i} w_{i}x_{i} = w^Tx$$\n",
    "\n",
    "### 4.1.1 Learning\n",
    "To learn the system we will calculate the squared distance between the input and the output and we minimaize this error.\n",
    "### 4.1.2. Delta rule\n",
    "#### Error measure\n",
    "Error measure is defined as the squared error of all trainig cases.\n",
    "$$ E = \\frac{1}{2} \\sum_{n \\in training} (t^n- x^n)^2 $$\n",
    "\n",
    "The error derivatives for the wieghts is: \n",
    "$$ \\frac{\\partial E}{\\partial w_i} = \\frac{1}{2} \\sum_n \\frac{\\partial y^n}{\\partial w_i} \\frac{dE^n}{dy^n} = - \\sum_n x_i^n (t^n- x^n) $$\n",
    "\n",
    "The batch delta rule changes the weights in proportion to their error derivatives summed over all training cases. The learning rule is then:\n",
    "$$ \\Delta w_i  = - \\epsilon \\frac{\\partial E}{\\partial w_i} = \\sum_n E x_i^n (t^n- x^n) $$\n",
    "\n",
    "This learning rule may not give the perfect answer.\n",
    "\n",
    "## 4.2. Logistic Neurons\n",
    "For multi layer nets with non-linear neurons we can use logistic neurons.\n",
    "\n",
    "The linear neuron has the following form:\n",
    "$$ z = b + \\sum_{i} w_{i}x_{i}$$      $$y = \\frac{1}{1+e^{-z}}$$ \n",
    "\n",
    "### 4.2.1 Learning\n",
    "The derivative of z in respect of w_i is: \n",
    "$$ \\frac{\\partial z}{\\partial w_i} = x_i $$\n",
    "\n",
    "The derivative of z in respect of w_i is: \n",
    "$$ \\frac{\\partial z}{\\partial x_i} = w_i $$\n",
    "\n",
    "The derivative of the output (y) in respect of z is: \n",
    "$$ \\frac{\\partial y}{\\partial z} = y(1-y) $$\n",
    "\n",
    "by using the chain rule we get:\n",
    "$$ \\frac{\\partial y}{\\partial w_i} = \\frac{\\partial z}{\\partial w_i} \\frac{dy}{dz} = x_iy(1-y) $$\n",
    "\n",
    "The learning rule is then:\n",
    "$$ \\frac{\\partial E}{\\partial w_i} = \\sum_{n} \\frac{\\partial y^n}{\\partial w_i} \\frac{\\partial E}{\\partial y^n} = - \\sum_{n} x_i^n y^n(1-y^n)(t^n-y^n) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
