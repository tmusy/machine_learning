{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Backpropagation\n",
    "The goal of the training is to find good features for the given problem. Instead of having a humand designing the features we let the computer repeatetly guess by randomly perturb the weights. However this would be a very inefficient way. The backpropagation algorithm is a much better.\n",
    "\n",
    "The idea behind the backpropagation:\n",
    "We don't know what the hidden units do, but we can compute how fast the **error** changes as we change a hidden activity.\n",
    "We do that by compute the error derivatives for all hidden units at the same time.\n",
    "\n",
    "FORMEL\n",
    "\n",
    "The backpropagation is an efficient way of computing the error **derivative dE/dw for every weight** on a single training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
